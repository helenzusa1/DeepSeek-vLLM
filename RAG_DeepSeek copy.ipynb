{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure RAG implementation using both Azure OpenAI and MaaP DeepSeek R1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Follow instructions in https://github.com/Azure-Samples/azure-search-python-samples/blob/main/Tutorial-RAG/Tutorial-rag.ipynb to set up:\n",
    "1. Azure Storage Account\n",
    "2. Azure AI Search Service\n",
    "3. Azure OpenAI Embedding Service\n",
    "4. (Optional) Azure OpenAI GPT-4o model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from -r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: azure-core in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.32.0)\n",
      "Requirement already satisfied: azure-search-documents==11.5.2 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (11.5.2)\n",
      "Requirement already satisfied: azure-storage-blob in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (12.24.1)\n",
      "Requirement already satisfied: azure-identity in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.20.0)\n",
      "Requirement already satisfied: openai in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from -r requirements.txt (line 6)) (1.64.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from -r requirements.txt (line 7)) (3.11.12)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from -r requirements.txt (line 8)) (8.1.5)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from -r requirements.txt (line 9)) (6.29.5)\n",
      "Requirement already satisfied: azure-common>=1.1 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from azure-search-documents==11.5.2->-r requirements.txt (line 3)) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from azure-search-documents==11.5.2->-r requirements.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from azure-search-documents==11.5.2->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from azure-core->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from azure-core->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from azure-storage-blob->-r requirements.txt (line 4)) (44.0.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 7)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 7)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 7)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 7)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 7)) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 7)) (1.18.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 8)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 8)) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 8)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 8)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 8)) (3.0.13)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 9)) (1.8.12)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 9)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 9)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 9)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 9)) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 9)) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 9)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 9)) (26.2.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 9)) (6.4.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob->-r requirements.txt (line 4)) (1.17.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 6)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 6)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (5.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 9)) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 9)) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 9)) (308)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r requirements.txt (line 5)) (2.10.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity->-r requirements.txt (line 5)) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 6)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from requests>=2.21.0->azure-core->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from requests>=2.21.0->azure-core->-r requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->-r requirements.txt (line 4)) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\helenzeng\\azure_rrag\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s f464793a-e174-43cd-b473-47ac97c91075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set endpoints and API keys for Azure services\n",
    "AZURE_SEARCH_SERVICE: str = \"https://xxxx.search.windows.net\"\n",
    "AZURE_SEARCH_KEY: str = \"xxxx\"\n",
    "AZURE_OPENAI_ACCOUNT: str = \"https://xxxx.openai.azure.com\"\n",
    "AZURE_OPENAI_KEY: str = \"xxxx\"\n",
    "AZURE_AI_MULTISERVICE_ACCOUNT: str = \"https://xxxx.cognitiveservices.azure.com/\"\n",
    "AZURE_AI_MULTISERVICE_KEY: str = \"xxxx\"\n",
    "AZURE_STORAGE_CONNECTION: str = \"ResourceId=/subscriptions/xxxxx/resourceGroups/xxxxx/providers/Microsoft.Storage/storageAccounts/xxxxx5;\"\n",
    "\n",
    "# Example connection string for a search service managed identity connection:\n",
    "# \"ResourceId=/subscriptions/FAKE-SUBCRIPTION=ID/resourceGroups/FAKE-RESOURCE-GROUP/providers/Microsoft.Storage/storageAccounts/FAKE-ACCOUNT;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the AI Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "credential = AzureKeyCredential(AZURE_SEARCH_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import get_bearer_token_provider\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "\n",
    "# Create a search index  \n",
    "index_name = \"py-rag-tutorial-idx\"\n",
    "index_client = SearchIndexClient(endpoint=AZURE_SEARCH_SERVICE, credential=credential)  \n",
    "fields = [\n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"locations\", type=SearchFieldDataType.Collection(SearchFieldDataType.String), filterable=True),\n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  \n",
    "    SearchField(name=\"text_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1024, vector_search_profile_name=\"myHnswProfile\")\n",
    "    ]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            parameters=AzureOpenAIVectorizerParameters(  \n",
    "                resource_url=AZURE_OPENAI_ACCOUNT,  \n",
    "                deployment_name=\"text-embedding-3-small\",\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            ),\n",
    "        ),  \n",
    "    ], \n",
    ")  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azure.search.documents.indexes._search_index_client.SearchIndexClient object at 0x0000029FD79D2BA0>\n"
     ]
    }
   ],
   "source": [
    "print(index_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Data Source\n",
    "Next step is to index the target dataset using Azure AI Search Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source 'py-rag-tutorial-ds' created or updated\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection\n",
    ")\n",
    "\n",
    "# Create a data source \n",
    "indexer_client = SearchIndexerClient(endpoint=AZURE_SEARCH_SERVICE, credential=credential)\n",
    "container = SearchIndexerDataContainer(name=\"nasa-ebooks-pdfs-all\")\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=\"py-rag-tutorial-ds\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=AZURE_STORAGE_CONNECTION,\n",
    "    container=container\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Indexer pipeline using Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "py-rag-tutorial-ss created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    EntityRecognitionSkill,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset,\n",
    "    CognitiveServicesAccountKey\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = \"py-rag-tutorial-ss\"\n",
    "\n",
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=2000,  \n",
    "    page_overlap_length=500,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_url=AZURE_OPENAI_ACCOUNT,  \n",
    "    deployment_name=\"text-embedding-3-small\",  \n",
    "    model_name=\"text-embedding-3-small\",\n",
    "    dimensions=1024,\n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")  \n",
    "    ],  \n",
    ")\n",
    "\n",
    "entity_skill = EntityRecognitionSkill(\n",
    "    description=\"Skill to recognize entities in text\",\n",
    "    context=\"/document/pages/*\",\n",
    "    categories=[\"Location\"],\n",
    "    default_language_code=\"en\",\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"locations\", target_name=\"locations\")\n",
    "    ]\n",
    ")\n",
    "  \n",
    "index_projections = SearchIndexerIndexProjection(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
    "                InputFieldMappingEntry(name=\"text_vector\", source=\"/document/pages/*/text_vector\"),\n",
    "                InputFieldMappingEntry(name=\"locations\", source=\"/document/pages/*/locations\"),  \n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ") \n",
    "\n",
    "cognitive_services_account = CognitiveServicesAccountKey(key=AZURE_AI_MULTISERVICE_KEY)\n",
    "\n",
    "skills = [split_skill, embedding_skill, entity_skill]\n",
    "\n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=skills,  \n",
    "    index_projection=index_projections,\n",
    "    cognitive_services_account=cognitive_services_account\n",
    ")\n",
    "  \n",
    "client = SearchIndexerClient(endpoint=AZURE_SEARCH_SERVICE, credential=credential)  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " py-rag-tutorial-idxr-1 is created and running. Give the indexer a few minutes before running a query.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = \"py-rag-tutorial-idxr-1\" \n",
    "\n",
    "indexer_parameters = None\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,\n",
    "    parameters=indexer_parameters\n",
    ")  \n",
    "\n",
    "# Create and run the indexer  \n",
    "indexer_client = SearchIndexerClient(endpoint=AZURE_SEARCH_SERVICE, credential=credential)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "\n",
    "print(f' {indexer_name} is created and running. Give the indexer a few minutes before running a query.')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the resulting AI Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.01666666753590107\n",
      "Chunk: national Aeronautics and Space Administration\n",
      "\n",
      "earth Science\n",
      "\n",
      "NASA Headquarters \n",
      "\n",
      "300 E Street SW \n",
      "\n",
      "Washington, DC 20546\n",
      "\n",
      "www.nasa.gov\n",
      "\n",
      "np-2018-05-2546-hQ\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Vector Search using text-to-vector conversion of the query string\n",
    "query = \"what's NASA's website?\"  \n",
    "\n",
    "search_client = SearchClient(endpoint=AZURE_SEARCH_SERVICE, credential=credential, index_name=index_name)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\"text_vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Chunk: {result['chunk']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up AzureOpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_credential = AzureKeyCredential(AZURE_OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_credential = AzureKeyCredential(AZURE_SEARCH_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "# Set up the Azure OpenAI client\n",
    "token_provider = get_bearer_token_provider(default_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "openai_client = AzureOpenAI(\n",
    "     api_version=\"2024-08-01-preview\",\n",
    "     azure_endpoint=AZURE_OPENAI_ACCOUNT,\n",
    "     azure_ad_token_provider=token_provider\n",
    " )\n",
    "\n",
    "deployment_name = \"gpt4o-helen\"\n",
    "\n",
    "# Set up the Azure Azure AI Search client\n",
    "search_client = SearchClient(\n",
    "     endpoint=AZURE_SEARCH_SERVICE,\n",
    "     index_name=index_name,\n",
    "     credential=search_credential\n",
    " )\n",
    "\n",
    "# Provide instructions to the model\n",
    "GROUNDED_PROMPT=\"\"\"\n",
    "You are an AI assistant that helps users learn from the information found in the source material.\n",
    "Answer the query using only the sources provided below.\n",
    "Use bullets if the answer has multiple points.\n",
    "If the answer is longer than 3 sentences, provide a summary.\n",
    "Answer ONLY with the facts listed in the list of sources below. Cite your source when you answer the question\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the sources below.\n",
    "Query: {query}\n",
    "Sources:\\n{sources}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the \"Retriever\" RAG component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<iterator object azure.core.paging.ItemPaged at 0x29fd993ead0>\n"
     ]
    }
   ],
   "source": [
    "# Provide the search query. \n",
    "# It's hybrid: a keyword search on \"query\", with text-to-vector conversion for \"vector_query\".\n",
    "# The vector query finds 50 nearest neighbor matches in the search index\n",
    "query=\"What's the NASA earth book about?\"\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\"text_vector\")\n",
    "\n",
    "# Set up the search results and the chat thread.\n",
    "# Retrieve the selected fields from the search index related to the question.\n",
    "# Search results are limited to the top 5 matches. Limiting top can help you stay under LLM quotas.\n",
    "search_results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"chunk\", \"locations\"],\n",
    "    top=5,\n",
    ")\n",
    "\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newlines could be in the OCR'd content or in PDFs, as is the case for the sample PDFs used for this tutorial.\n",
    "# Use a unique separator to make the sources distinct. \n",
    "# We chose repeated equal signs (=) followed by a newline because it's unlikely the source documents contain this sequence.\n",
    "sources_formatted = \"=================\\n\".join([f'TITLE: {document[\"title\"]}, CONTENT: {document[\"chunk\"]}, LOCATIONS: {document[\"locations\"]}' for document in search_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the \"Generator\" RAG component using AOAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NASA Earth book is a work that lies at the intersection of science and art. It explores how NASA has studied Earth's physical processes from beneath its crust to the edge of the atmosphere, using innovative tools to examine the water cycle, carbon cycle, ocean circulation, and the movement of heat. The book features inspiring images that tell the story of a 4.5-billion-year-old planet, showcasing the interconnected dance of land, wind, water, ice, and air as viewed from space. \n",
      "\n",
      "The book emphasizes NASA's unique vantage point in observing and understanding Earth, while also celebrating the planet's inherent beauty and complexity through a collection of vivid, scientifically accurate images (source: page-8.pdf).\n"
     ]
    }
   ],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": GROUNDED_PROMPT.format(query=query, sources=sources_formatted)\n",
    "        }\n",
    "    ],\n",
    "    model=deployment_name\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the \"Generator\" RAG component using DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I'm trying to figure out what the NASA Earth Book is about. Let me look through the sources provided. \n",
      "\n",
      "Starting with page-8.pdf, it says the book stands at the intersection of science and art. It talks about NASA studying Earth in novel ways using tools to look at physical processes, from beneath the crust to the atmosphere. It mentions looking at Earth in macrocosm and microcosm, like mountain streams and jet streams. It also says they examine Earth as a system, looking at cycles like the water and carbon cycles, ocean circulation, and heat movement. They measure particles, gases, energy, and fluids, and study light—how it reflects, refracts, etc. It's like they're taking a step back to admire Earth's beauty and see it as a jewel from space. The images chosen are meant to inspire, showing the planet's diversity and that no human imagination can match its real beauty.\n",
      "\n",
      "Moving to page-175.pdf, it's about the authors. Michael Carlowicz is the managing editor, and Kathy Carroll supports the Earth Science Division. They have backgrounds in writing about Earth science and have worked for various organizations. They also mention their hobbies, like baseball and music.\n",
      "\n",
      "Page-171.pdf has acknowledgments, mentioning people who contributed to the book's design, layout, reporting, and imagery. It also thanks the Landsat teams and NASA Earth Observatory for making imagery available to the public.\n",
      "\n",
      "Page-9.pdf includes a quote from Lewis Thomas about Earth being alive and exuberant, comparing it to a live creature.\n",
      "\n",
      "Putting it all together, the book seems to be a visual and scientific exploration of Earth, showcasing its systems, processes, and beauty through art and science. It's a celebration of Earth from space, using images to tell its story and inspire. The authors and contributors have backgrounds in science and outreach, and the book is accessible to the public through publicly available data.\n",
      "</think>\n",
      "\n",
      "The NASA Earth Book is a visual and scientific exploration of our planet, blending art and science to showcase Earth's systems, processes, and natural beauty. It examines Earth from both a macroscopic and microscopic perspective, studying everything from beneath the crust to the atmosphere. The book highlights Earth as a dynamic system, exploring cycles like the water and carbon cycles, ocean circulation, and heat movement. It also delves into the study of light and its interaction with Earth, using images to capture the planet's diversity and inspire awe.\n",
      "\n",
      "The authors, Michael Carlowicz and Kathy Carroll, bring a background in Earth science and outreach, having worked for various organizations and contributing to popular science books. The book's creation involved a team of contributors, including scientists, designers, and visual experts, who transformed data into stunning visuals. The Landsat teams and NASA Earth Observatory are recognized for making Earth imagery accessible to the public, emphasizing science's accessibility.\n",
      "\n",
      "In summary, the book is a celebration of Earth, offering a unique perspective from space, and inspiring appreciation for the planet as it is."
     ]
    }
   ],
   "source": [
    "# If using my own subscription then execute the below block.\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://r1-prod-helen.centralus.inference.ml.azure.com/v1\",\n",
    "    api_key=\"xxxx\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": GROUNDED_PROMPT.format(query=query, sources=sources_formatted)}\n",
    "  ],\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  print(chunk.choices[0].delta.content, end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
